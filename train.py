import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
from tqdm import tqdm
import segmentation_models_pytorch as smp  # â˜…â˜…â˜… æ ¸å¿ƒæ­¦å™¨ï¼šä½¿ç”¨ç¾æˆçš„å¼·å¤§åˆ†å‰²æ¨¡å‹åº«

from dataset_cts_v5 import CTSDatasetV5, DATA_ROOT

# ===== 1. åƒæ•¸è¨­å®š =====
BATCH_SIZE = 1  # é†«å­¸å½±åƒè¼ƒå¤§ï¼Œé¡¯å¡è¨˜æ†¶é«”æœ‰é™æ™‚è¨­ç‚º 1
EPOCHS = 100    # è¨“ç·´ç¸½å›æ•¸
LEARNING_RATE = 1e-4  # â˜… ä½¿ç”¨é è¨“ç·´æ¨¡å‹æ™‚ï¼Œå­¸ç¿’ç‡è¦èª¿å° (1e-4)ï¼Œé¿å…ç ´å£å­¸å¥½çš„ç‰¹å¾µ
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ¬Šé‡ç­–ç•¥ï¼šMN æ¥µå°ï¼Œæ¬Šé‡åŠ é‡ (10.0)ï¼Œå¼·è¿«æ¨¡å‹é—œæ³¨ç¥ç¶“
# [èƒŒæ™¯, MN, FT, CT]
CLASS_WEIGHTS = torch.tensor([0.5, 10.0, 2.0, 2.0], device=DEVICE)

CHECKPOINT_DIR = "checkpoints_sota"
os.makedirs(CHECKPOINT_DIR, exist_ok=True)

# ===== 2. å®šç¾© SOTA æ¨¡å‹ (ä½¿ç”¨ SMP) =====
class CTSModel(nn.Module):
    def __init__(self, n_classes=4):
        super().__init__()
        # ä½¿ç”¨ U-Net++ æ¶æ§‹ (æ¯” U-Net æ›´å¼·ï¼Œæœ‰æ›´å¯†é›†çš„è·³æ¥)
        # æ­é… EfficientNet-B3 éª¨å¹¹ (ç‰¹å¾µæå–èƒ½åŠ›å¼·)
        # encoder_weights="imagenet": ä½¿ç”¨ ImageNet é è¨“ç·´æ¬Šé‡ (è½‰ç§»å­¸ç¿’)
        self.model = smp.UnetPlusPlus(
            encoder_name="efficientnet-b3",  
            encoder_weights="imagenet",      
            in_channels=2,                   # è¼¸å…¥é€šé“ = 2 (T1 + T2)
            classes=n_classes,               # è¼¸å‡ºé¡åˆ¥ = 4
        )

    def forward(self, x):
        return self.model(x)

# ===== 3. è©•ä¼°å‡½å¼ (Dice Score) =====
def compute_dice_union(pred, target, cls_id):
    """è¨ˆç®— Dice Coefficient"""
    if cls_id == 3: # CT (è…•éš§é“) çš„ç‰¹æ®Šé‚è¼¯ï¼šUnion
        # CT åŒ…å«äº† MN, FT, CT æ‰€æœ‰å€åŸŸï¼Œæ‰€ä»¥åªè¦é æ¸¬æ˜¯ 1, 2, æˆ– 3 éƒ½ç®—åœ¨ CT ç¯„åœå…§
        p = (pred == 1) | (pred == 2) | (pred == 3)
        t = (target == 1) | (target == 2) | (target == 3)
    else:
        # å…¶ä»–çµ„ç¹” (MN, FT) å°±æ­£å¸¸è¨ˆç®—
        p = (pred == cls_id)
        t = (target == cls_id)
    
    # äº¤é›† (Intersection)
    inter = (p & t).sum()
    # è¯é›† (Sum of areas)
    union = p.sum() + t.sum()
    
    if union == 0: return 1.0 # å…©é‚Šéƒ½æ˜¯ç©ºçš„ï¼Œç®—æ»¿åˆ†
    return 2.0 * inter / (union + 1e-6) # åŠ ä¸Š 1e-6 é¿å…é™¤ä»¥é›¶

# ===== 4. è¨“ç·´å–®ä¸€ Fold (ä¸€æŠ˜) =====
def train_one_fold(fold_idx, train_ids, val_ids, test_ids):
    print(f"\nâš¡ Fold {fold_idx+1}/5 | Train:{train_ids} | Val:{val_ids} | Test:{test_ids}")
    
    # æº–å‚™ Dataset
    train_ds = CTSDatasetV5(root=DATA_ROOT, case_ids=train_ids, augment=True) # è¨“ç·´é›†è¦é–‹å¢å¼·
    val_ds   = CTSDatasetV5(root=DATA_ROOT, case_ids=val_ids, augment=False)
    test_ds  = CTSDatasetV5(root=DATA_ROOT, case_ids=test_ids, augment=False)
    
    # æº–å‚™ DataLoader
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0)
    test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0)

    # åˆå§‹åŒ–æ¨¡å‹ã€å„ªåŒ–å™¨ã€æ’ç¨‹å™¨
    model = CTSModel(n_classes=4).to(DEVICE)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)
    # ReduceLROnPlateau: ç•¶ loss å¡ä½ä¸é™æ™‚ï¼Œè‡ªå‹•æŠŠå­¸ç¿’ç‡æ¸›åŠ
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)
    
    best_val_score = 0.0
    best_model_state = None
    patience = 20 # æ—©åœæ©Ÿåˆ¶ï¼šå¦‚æœ 20 å€‹ epoch éƒ½æ²’é€²æ­¥å°±åœ
    counter = 0

    # --- Training Loop (è¨“ç·´è¿´åœˆ) ---
    for epoch in range(1, EPOCHS + 1):
        model.train() # åˆ‡æ›åˆ°è¨“ç·´æ¨¡å¼
        epoch_loss = 0.0
        
        # tqdm é€²åº¦æ¢
        with tqdm(total=len(train_loader), desc=f"Ep {epoch}/{EPOCHS}", unit="batch", leave=False) as pbar:
            for imgs, labels in train_loader:
                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE).long()
                
                optimizer.zero_grad()           # 1. æ¢¯åº¦æ­¸é›¶
                logits = model(imgs)            # 2. æ¨¡å‹é æ¸¬
                # 3. è¨ˆç®— Loss (Cross Entropy)
                loss = F.cross_entropy(logits, labels, weight=CLASS_WEIGHTS)
                loss.backward()                 # 4. åå‘å‚³æ’­
                optimizer.step()                # 5. æ›´æ–°æ¬Šé‡
                
                epoch_loss += loss.item()
                pbar.set_postfix({"loss": f"{loss.item():.4f}"})
                pbar.update(1)
        
        # --- Validation (é©—è­‰éšæ®µ) ---
        model.eval() # åˆ‡æ›åˆ°è©•ä¼°æ¨¡å¼ (é—œé–‰ Dropout ç­‰)
        val_dice_sum = 0.0; n_val = 0
        with torch.no_grad(): # ä¸è¨ˆç®—æ¢¯åº¦ï¼Œçœè¨˜æ†¶é«”
            for imgs, labels in val_loader:
                imgs = imgs.to(DEVICE)
                logits = model(imgs)
                preds = torch.argmax(logits, dim=1).cpu().numpy()[0] # å–å‡ºé æ¸¬çµæœ
                lbl = labels.numpy()[0]
                
                # è¨ˆç®— MN å’Œ CT çš„ Dice åˆ†æ•¸
                d1 = compute_dice_union(preds, lbl, 1) # MN
                d3 = compute_dice_union(preds, lbl, 3) # CT
                val_dice_sum += (d1 + d3) / 2.0
                n_val += 1
        
        avg_val_score = val_dice_sum / n_val
        scheduler.step(avg_val_score) # æ ¹æ“šåˆ†æ•¸èª¿æ•´å­¸ç¿’ç‡
        
        print(f"   [Ep {epoch}] Loss: {epoch_loss/len(train_loader):.4f} | Val Score: {avg_val_score:.4f}", end="")
        
        # å„²å­˜æœ€ä½³æ¨¡å‹
        if avg_val_score > best_val_score:
            best_val_score = avg_val_score
            best_model_state = model.state_dict()
            counter = 0
            print(" ğŸŒŸ New Best!") # å‰µæ–°é«˜
        else:
            counter += 1
            print("")
        
        # æ—©åœæª¢æŸ¥
        if counter >= patience:
            print("ğŸ›‘ Early Stopping")
            break

    # --- è¨“ç·´çµæŸï¼Œå­˜æª”ä¸¦é€²è¡Œæ¸¬è©¦ ---
    save_path = os.path.join(CHECKPOINT_DIR, f"best_fold_{fold_idx+1}.pth")
    if best_model_state:
        torch.save(best_model_state, save_path)
        model.load_state_dict(best_model_state) # è¼‰å…¥æœ€ä½³æ¬Šé‡é€²è¡Œæ¸¬è©¦
    
    # åœ¨ Test Set ä¸Šè·‘ä¸€æ¬¡åˆ†æ•¸
    model.eval()
    mn_list, ft_list, ct_list = [], [], []
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs = imgs.to(DEVICE)
            logits = model(imgs)
            preds = torch.argmax(logits, dim=1).cpu().numpy()[0]
            lbl = labels.numpy()[0]
            mn_list.append(compute_dice_union(preds, lbl, 1))
            ft_list.append(compute_dice_union(preds, lbl, 2))
            ct_list.append(compute_dice_union(preds, lbl, 3))
    
    final_mn = np.mean(mn_list)
    final_ft = np.mean(ft_list)
    final_ct = np.mean(ct_list)
    print(f"âœ… Fold {fold_idx+1} Result >> MN: {final_mn:.4f}, FT: {final_ft:.4f}, CT: {final_ct:.4f}")
    return final_mn, final_ft, final_ct

# ===== 5. åŸ·è¡Œ 5-Fold äº¤å‰é©—è­‰ =====
def run_sota_training():
    # å®šç¾© 5 å€‹ Fold çš„åˆ†çµ„ (ä¾æ“š PPT è¦å‰‡)
    pairs = [["8", "9"], ["6", "7"], ["4", "5"], ["2", "3"], ["0", "1"]]
    mn_all, ft_all, ct_all = [], [], []
    
    print(f"ğŸš€ é–‹å§‹ SOTA è¨“ç·´ (U-Net++ with EfficientNet-B3)")
    
    for i in range(5):
        pair = pairs[i]
        val_ids = [pair[0]]; test_ids = [pair[1]] # è¼ªæµç•¶é©—è­‰å’Œæ¸¬è©¦
        train_ids = []
        for p in pairs:
            if p != pair: train_ids.extend(p) # å…¶ä»–éƒ½ç•¶è¨“ç·´
        
        mn, ft, ct = train_one_fold(i, train_ids, val_ids, test_ids)
        mn_all.append(mn); ft_all.append(ft); ct_all.append(ct)

    # è¼¸å‡ºæœ€çµ‚å¹³å‡æˆç¸¾
    print("\n==================================")
    print(f"ğŸ† SOTA 5-Fold æœ€çµ‚å¹³å‡åˆ†æ•¸")
    print(f"Mean MN: {np.mean(mn_all):.4f}")
    print(f"Mean FT: {np.mean(ft_all):.4f}")
    print(f"Mean CT: {np.mean(ct_all):.4f}")
    print("==================================")

if __name__ == "__main__":
    run_sota_training()
